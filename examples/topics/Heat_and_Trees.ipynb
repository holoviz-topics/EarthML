{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Heat Islands and Street Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll be exploring the urban heat island effect by looking at the impact on surface temperature of roof color and street trees. We'll be replicating the process described here: http://urbanspatialanalysis.com/urban-heat-islands-street-trees-in-philadelphia/ but using Python tools rather than ESRI.\n",
    "\n",
    "\n",
    "**Extra packages:** To run this notebook, you'll need the PyViz tools and a library of *top of atmosphere* calculations from [`rio-toa`](https://github.com/mapbox/rio-toa): `pip install rio-toa`\n",
    "\n",
    "**Data sources:** This notebook uses Landsat data from Google Cloud Storage as well as some geographic data from OpenDataPhilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "\n",
    "from geoviews.tile_sources import EsriImagery\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some extra info about Landsat data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_info = pd.DataFrame([\n",
    "        (1,  \"Aerosol\", \" 0.43 - 0.45\",    0.440,  \"30\",         \"Coastal aerosol\"),\n",
    "        (2,  \"Blue\",    \" 0.45 - 0.51\",    0.480,  \"30\",         \"Blue\"),\n",
    "        (3,  \"Green\",   \" 0.53 - 0.59\",    0.560,  \"30\",         \"Green\"),\n",
    "        (4,  \"Red\",     \" 0.64 - 0.67\",    0.655,  \"30\",         \"Red\"),\n",
    "        (5,  \"NIR\",     \" 0.85 - 0.88\",    0.865,  \"30\",         \"Near Infrared (NIR)\"),\n",
    "        (6,  \"SWIR1\",   \" 1.57 - 1.65\",    1.610,  \"30\",         \"Shortwave Infrared (SWIR) 1\"),\n",
    "        (7,  \"SWIR2\",   \" 2.11 - 2.29\",    2.200,  \"30\",         \"Shortwave Infrared (SWIR) 2\"),\n",
    "        (8,  \"Panc\",    \" 0.50 - 0.68\",    0.590,  \"15\",         \"Panchromatic\"),\n",
    "        (9,  \"Cirrus\",  \" 1.36 - 1.38\",    1.370,  \"30\",         \"Cirrus\"),\n",
    "        (10, \"TIRS1\",   \"10.60 - 11.19\",   10.895, \"100 * (30)\", \"Thermal Infrared (TIRS) 1\"),\n",
    "        (11, \"TIRS2\",   \"11.50 - 12.51\",   12.005, \"100 * (30)\", \"Thermal Infrared (TIRS) 2\")],\n",
    "    columns=['Band', 'Name', 'Wavelength Range (µm)', 'Nominal Wavelength (µm)', 'Resolution (m)', 'Description']).set_index([\"Band\"])\n",
    "band_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "For this example, we will be using landsat data stored on Google Cloud Storage. Since these data are accessed via https, there is no guaranteed directory structure, so we will need to specify the url pointing to each file and then iterate over the files to create a concatenated dataset. We use jinja template notation in intake to pass parameters to the `urlpath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('../catalog.yml')\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the `google_landsat_band` looks like:\n",
    "\n",
    "```yml\n",
    "google_landsat_band:\n",
    "    description: Landsat bands from Google Cloud Storage\n",
    "    driver: rasterio\n",
    "    parameters:\n",
    "      path:\n",
    "        description: landsat path\n",
    "        type: int\n",
    "      row:\n",
    "        description: landsat row\n",
    "        type: int\n",
    "      product_id:\n",
    "        description: landsat file id\n",
    "        type: str\n",
    "      band:\n",
    "        description: band\n",
    "        type: int\n",
    "    args:\n",
    "      urlpath: https://storage.googleapis.com/gcp-public-data-landsat/LC08/01/{{ '%03d' % path }}/{{ '%03d' % row }}/{{ product_id }}/{{ product_id }}_B{{ band }}.TIF\n",
    "      chunks:\n",
    "        band: 1\n",
    "        x: 256\n",
    "        y: 256\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following might feel a bit arbitrary, but we have chosen the path and row corresponding to the area over Philadelphia using the [earth explorer](https://earthexplorer.usgs.gov/). We have also found the id of the particular date of interest using the same tool. With these values in hand, we can access parts of each file on Google Cloud Storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 14\n",
    "row = 32\n",
    "product_id = 'LC08_L1TP_014032_20160727_20170222_01_T1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workflow, we don't ever need to load in all of the data, just the metadata and some of the actual data. We do need to use \"backoff\" to avoid transient error conditions for https access for the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from time import sleep\n",
    "\n",
    "def get_band_with_exponential_backoff(path, row, product_id, band, \n",
    "                                      maximum_backoff=32):\n",
    "    \"\"\"\n",
    "    Google Cloud Storage recommends using exponential backoff \n",
    "    when accessing the API. \n",
    "    \n",
    "    https://cloud.google.com/storage/docs/exponential-backoff\n",
    "    \"\"\"\n",
    "    n = backoff = 0\n",
    "    while backoff < maximum_backoff:\n",
    "        try:\n",
    "            return cat.google_landsat_band(path=path, row=row, \n",
    "                                           product_id=product_id,\n",
    "                                           band=band).to_dask()\n",
    "        except:\n",
    "            backoff = min(2**n + random(), maximum_backoff)\n",
    "            sleep(backoff)\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the bands\n",
    "# bands = range(1, 12)\n",
    "\n",
    "# OR skip band 8 for now since it is at a different resolution and transform\n",
    "bands = [1, 2, 3, 4, 5, 6, 7, 9, 10, 11]\n",
    "\n",
    "datasets = []\n",
    "for band in bands:\n",
    "    da = get_band_with_exponential_backoff(path=path, row=row, product_id=product_id, band=band)\n",
    "    da = da.assign_coords(band=[band])\n",
    "    datasets.append(da)\n",
    "    \n",
    "ds = xr.concat(datasets, 'band', compat='identical')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in metadata regarding these particular Landsat images from the associated matlab.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_landsat_metadata(path, row, product_id):\n",
    "    \"\"\"Load Landsat metadata for path, row, product_id from Google Cloud Storage\n",
    "    \"\"\"\n",
    "    def parse_type(x):\n",
    "        try: \n",
    "            return eval(x)\n",
    "        except:\n",
    "            return x\n",
    "    \n",
    "    baseurl = 'https://storage.googleapis.com/gcp-public-data-landsat/LC08/01'\n",
    "    suffix = f'{path:03d}/{row:03d}/{product_id}/{product_id}_MTL.txt'\n",
    "    \n",
    "    df = intake.open_csv(\n",
    "        urlpath=f'{baseurl}/{suffix}',\n",
    "        csv_kwargs={'sep': '=',\n",
    "                    'header': None,\n",
    "                    'names': ['index', 'value'],\n",
    "                    'skiprows': 2,\n",
    "                    'converters': {'index': (lambda x: x.strip()),\n",
    "                                   'value': parse_type}}).read()\n",
    "    metadata = df.set_index('index')['value']\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = load_google_landsat_metadata(path, row, product_id)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-setting to area of interest\n",
    "\n",
    "So far we haven't downloaded any band data. Since we know that we are interested in Philadelphia, we can just take a smaller square of data that covers the extents of the city. First we need to know the projection of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert that into something directly usable for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ccrs.epsg(32618)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we were just looking for one particular point we could use that point, converted to the coordinate system of the data, and then select the data nearest to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_center, y_center = crs.transform_point(-75.1652, 39.9526, ccrs.PlateCarree())\n",
    "nearest_to_center = ds.sel(x=x_center, y=y_center, method='nearest')\n",
    "print(nearest_to_center.compute())\n",
    "\n",
    "nearest_to_center.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, though, we are interested in a subset of data that covers that city of Philadelphia. So we need some geometry to specify the bounds of the city. We can get a GeoJSON of neighborhood data from [OpenDataPhilly](https://www.opendataphilly.org/dataset/philadelphia-neighborhoods/resource/6c61f240-aafe-478e-b993-b75fd09a93d6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/azavea/geo-data/raw/master/Neighborhoods_Philadelphia/Neighborhoods_Philadelphia.geojson'\n",
    "geoms = gpd.read_file(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach shown below is somewhat simplistic in that we will use the map to iteratively select the area of interest by tweaking the bounds out from the central lat, lon of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ds.sel(x=slice(x_center-1.2e4, x_center+1.9e4), y=slice(y_center+2.1e4, y_center-1.2e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = subset.sel(band=3).hvplot(rasterize=True, crs=crs, height=500, width=600).redim(x=\"Longitude\", y=\"Latitude\")\n",
    "plot.options(tools=[]) * geoms.hvplot(geo=True, alpha=.5, c='mapname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at our map and ensured that the area covers the city, we will just take this chunk of the bands to use for further analyses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = subset\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDVI\n",
    "\n",
    "We'll calculate NDVI but we won't yet do any computations -- our bands are actually dask arrays, which allow for lazy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI = (ds.sel(band=5) - ds.sel(band=4)) / (ds.sel(band=5) + ds.sel(band=4))\n",
    "NDVI = NDVI.where(NDVI < np.inf)\n",
    "NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize NDVI, the data will need to be loaded and the NDVI computed. We can expect this to take some non-trivial amount of time (on the order of 20 sec on my machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = NDVI.hvplot(datashade=True, x='x', y='y', crs=crs, height=500, width=500, cmap='viridis')\n",
    "\n",
    "# We'll use a transparent rasterized version of the plot for hover text\n",
    "p_hover = NDVI.hvplot(rasterize=True, x='x', y='y', crs=crs, height=500, width=500, alpha=0, colorbar=False)\n",
    "\n",
    "p * p_hover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate land surface temperature\n",
    "\n",
    "Given the NDVI calculated above, we can determine land surface temperature. For ease, we'll use some *top of atmosphere* calculations that have already been written up as Python functions as part of rasterio work in the `rio_toa` module. We'll also need to specify one more for transforming satellite temperature (brightness temp) to land surface temperature. For these calculations we'll use both Thermal Infrared bands - 10 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rio_toa import brightness_temp, toa_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_surface_temp(BT, w, NDVI):\n",
    "    \"\"\"Calculate land surface temperature of Landsat 8\n",
    "    \n",
    "    temp = BT/1 + w * (BT /p) * ln(e)\n",
    "    \n",
    "    BT = At Satellite temperature (brightness)\n",
    "    w = wavelength of emitted radiance (μm)\n",
    "    \n",
    "    where p = h * c / s (1.439e-2 mK)\n",
    "    \n",
    "    h = Planck's constant (Js)\n",
    "    s = Boltzmann constant (J/K)\n",
    "    c = velocity of light (m/s)\n",
    "    \"\"\"\n",
    "    h = 6.626e-34\n",
    "    s = 1.38e-23\n",
    "    c = 2.998e8\n",
    "    \n",
    "    p = (h * c / s) * 1e6\n",
    "    \n",
    "    Pv = (NDVI - NDVI.min() / NDVI.max() - NDVI.min())**2\n",
    "    e = 0.004 * Pv + 0.986\n",
    "    \n",
    "    return BT / 1 + w * (BT / p) * np.log(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll set up a helper function to retrieve all the parameters from the metadata and general Landsat info table, and calculate the land surface temperature for bands 10 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_surface_temp_for_band(band):\n",
    "    # params from general Landsat info\n",
    "    w = band_info.loc[band]['Nominal Wavelength (µm)']\n",
    "    \n",
    "    # params from specific Landsat data text file for these images\n",
    "    ML = metadata[f'RADIANCE_MULT_BAND_{band}']\n",
    "    AL = metadata[f'RADIANCE_ADD_BAND_{band}']\n",
    "    K1 = metadata[f'K1_CONSTANT_BAND_{band}']\n",
    "    K2 = metadata[f'K2_CONSTANT_BAND_{band}']\n",
    "    \n",
    "    at_satellite_temp = brightness_temp.brightness_temp(ds.sel(band=band).values, ML, AL, K1, K2)\n",
    "    \n",
    "    return land_surface_temp(at_satellite_temp, w, NDVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 10\n",
    "temp_10 = land_surface_temp_for_band(band).compute()\n",
    "temp_10_f = toa_utils.temp_rescale(temp_10, 'F')\n",
    "band_10=ds.sel(band=band).copy(data=temp_10_f).hvplot(rasterize=True, x='x', y='y', cmap='fire_r', \n",
    "                                                      crs=crs, height=500, width=450)\n",
    "\n",
    "band = 11\n",
    "temp_11 = land_surface_temp_for_band(band).compute()\n",
    "temp_11_f = toa_utils.temp_rescale(temp_11, 'F')\n",
    "band_11=ds.sel(band=band).copy(data=temp_11_f).hvplot(rasterize=True, x='x', y='y', cmap='fire_r', \n",
    "                                                      crs=crs, height=500, width=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results from the two different bands, noticing that the colorbars are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_10.relabel('Band 10') + band_11.relabel('Band 11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take the mean of the calculated land surface temperature for each of the bands and mimic the colormap used in the project that we are duplicating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp = (temp_10 + temp_11) / 2\n",
    "mean_temp_f = toa_utils.temp_rescale(mean_temp, 'F')\n",
    "\n",
    "data = ds[0].copy(data=mean_temp_f)\n",
    "p = (data\n",
    "    .hvplot(rasterize=True, x='x', y='y', crs=crs, height=500, width=600, cmap='rainbow', alpha=.5, legend=False)\n",
    "    .relabel('Mean Surface Temp (F)'))\n",
    "\n",
    "p * EsriImagery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the hot spots are located over warehouse roofs and parking lots. This becomes even more visible when just the temperatures greater than 90F are displayed. To show this, we'll make a special colormap that just includes high intensity reds that are found at the top of the `fire_r` colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "\n",
    "special_cmap = cc.fire[::-1][90:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[0].copy(data=mean_temp_f.where(mean_temp_f > 90))\n",
    "thresholded_temp_p = (data\n",
    "    .hvplot(x='x', y='y', cmap=special_cmap, crs=crs, height=500, width=450, \n",
    "            colorbar=False, legend=False, rasterize=True)\n",
    "    .relabel('Mean Temp (F) > 90')\n",
    "    .redim(value='Temperature (F)'))\n",
    "\n",
    "thresholded_temp_p + thresholded_temp_p.options(alpha=.3) * EsriImagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in the Street Tree data\n",
    "\n",
    "OpenDataPhilly released an inventory of all the street trees in the city. Street trees are trees that are planted along streets, not those in parks and private property. The original analysis considered these 100,000 points too many to plot, but that's nothing to `datashader`, which is happy with billions of points even on a laptop.\n",
    "\n",
    "It is hypothesized that where there are more trees the land surface temperature will be less extreme. To explore this, we will overlay street trees with the thresholded land surface temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://data.phl.opendata.arcgis.com/datasets/957f032f9c874327a1ad800abd887d17_0.geojson'\n",
    "trees = gpd.read_file(url)\n",
    "import geoviews as gv\n",
    "gv.Points.datatype = ['geodataframe', 'dictionary'] # Temporary geoviews workaround\n",
    "trees.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_p = trees.hvplot(geo=True, datashade=True, height=500, width=400, legend=False, dynspread=30).relabel('Street Tree Density')\n",
    "\n",
    "thresholded_temp_p.options(alpha=.5) * tree_p.options(alpha=.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
