{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering Example.\n",
    "\n",
    "The image loaded here is a cropped portion of the ``MERCATOR_LC80210392016114LGN00_B10.TIF`` LANDSAT image included as a public [datashader example](http://datashader.org/topics/landsat.html).\n",
    "\n",
    "In addition to `dask-ml`, we'll use `rasterio` to read the data and `matplotlib` to plot the figures.\n",
    "I'm just working on my laptop, so we could use either the threaded or distributed scheduler. I'll use the distributed scheduler for the diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "import dask.array as da\n",
    "from dask_ml.cluster import SpectralClustering\n",
    "from dask.distributed import Client\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "cat = intake.open_catalog('../catalog.yml')\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = cat.landsat_sample.read_chunked()\n",
    "#xa = cat.midwest_mosaic.read_chunked()\n",
    "xa = xa.squeeze(dim='concat_dim', drop=True)[0]\n",
    "xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale for the clustering algorithm\n",
    "xa = xa.astype(float)\n",
    "xa = (xa - xa.mean()) / xa.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image (cmap='viridis')\n",
    "regrid(hv.Image(xa.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input = xa.stack(z=('y', 'x'))\n",
    "flat_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll reshape the image to be how dask-ml / scikit-learn expect it: `(n_samples, n_features)` where n_features is 1 in this case. Then we'll persist that in memory. We still have a small dataset at this point. The large dataset, which dask helps us manage, is the intermediate `n_samples x n_samples` array that spectral clustering operates on. For our 2,500 x 2,500 pixel subset, that's ~50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flat_input.expand_dims(dim='e', axis=1).values.astype('float')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = da.from_array(X, chunks=100_000)\n",
    "X = client.persist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll fit the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SpectralClustering(n_clusters=4, random_state=0,\n",
    "                         gamma=None,\n",
    "                         kmeans_params={'init_max_iter': 5},\n",
    "                         persist_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clf.assign_labels_.labels_.compute()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstack_output(flat_input, output_values):\n",
    "    \"\"\"Unstack this output into the original input shape\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    flat_input : DataArray\n",
    "        Flattened DataArray used as the input to the ML pipeline\n",
    "    output_values : np.ndarray\n",
    "        Output values from ML pipeline in same shape as `flat_input`\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output: DataArray with same shape as original input\n",
    "    \"\"\"\n",
    "    dims = flat_input.dims\n",
    "    output = flat_input.copy()\n",
    "    output.values = output_values\n",
    "    \n",
    "    for dim in dims:\n",
    "        output = output.unstack(dim=dim)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = unstack_output(flat_input, labels)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image (cmap='viridis')\n",
    "hv.Image(xa).relabel('Image') + hv.Image(output).relabel('Clustered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
