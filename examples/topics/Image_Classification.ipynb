{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satellite images often need to be classified (assigned to a fixed set of types) or to be used for detection of various features of interest.  Here we will look at the classification case, using labelled satellite images from various categories from the [UCMerced LandUse dataset](http://weegee.vision.ucmerced.edu/datasets/landuse.html). scikit-learn is useful for general numeric data types, but it doesn't have significant support for working with images. Luckily, there are various deep-learning and convolutional-network libraries that do support images well, including Keras (backed by TensorFlow) as we will use here. To run this notebook, you will first need to download the dataset and put it in ../data/.\n",
    "\n",
    "<!-- Direct link: http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import intake\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import geoviews as gv\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "\n",
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the classes and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/UCMerced_LandUse/Images/'\n",
    "classes = np.array([f.split('/')[-1] for f in glob.glob(path+'*')])\n",
    "files = {c: glob.glob(os.path.join(path, c, '*')) for c in classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split files into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list(np.random.choice(np.arange(100), 80, False))\n",
    "test_set = [i for i in range(100) if i not in train_set]\n",
    "\n",
    "train_files = {c: [f for f in fs if int(f[-6:-4]) in train_set] for c, fs in files.items()}\n",
    "test_files  = {c: [f for f in fs if int(f[-6:-4]) in test_set]  for c, fs in files.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to sample from train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(cls, set='training'):\n",
    "    files = train_files if set == 'training' else test_files\n",
    "    flist = list(files[cls])\n",
    "    f = flist[np.random.randint(len(flist))]\n",
    "    return gv.RGB.load_tiff(f).relabel(cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples are loaded as xarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample(classes[0]).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But are actually visualizable RGB Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.Layout([get_sample(s) for s in np.random.choice(classes, 4)]).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "A simple convolutional network using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(21))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the data\n",
    "\n",
    "We will define a generator that loads chunks of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntraining = 10000\n",
    "\n",
    "def get_array(rgb):\n",
    "    h, w = rgb.interface.shape(rgb, True)\n",
    "    b = np.random.randint(h-100)\n",
    "    l = np.random.randint(w-100)\n",
    "    return np.dstack([np.flipud(rgb.dimension_values(d, flat=False)[b:b+100, l:l+100])/255 for d in rgb.vdims])\n",
    "\n",
    "choices = np.random.choice(classes, ntraining)\n",
    "class_list = list(classes)\n",
    "\n",
    "def gen_samples(choices, set='training'):\n",
    "    \"Generates random arrays along with class labels\"\n",
    "    for c in choices:\n",
    "        labels = np.zeros((21,))\n",
    "        labels[class_list.index(c)] = 1\n",
    "        yield get_array(get_sample(c, set))[np.newaxis, :], labels[np.newaxis, :]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit_generator(gen_samples(choices), steps_per_epoch=100, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hv.Curve(history.history['loss'], 'Iteration', 'Loss'    ).options(width=400) +\n",
    " hv.Curve(history.history['acc'],  'Iteration', 'Accuracy').options(width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us test the predictions on the test set, first visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(cls):\n",
    "    sample = get_sample(cls, 'test')\n",
    "    array = get_array(sample)[np.newaxis, ...]\n",
    "    p = model.predict(array).argmax()\n",
    "    p = classes[p]\n",
    "    return sample.relabel('Predicted: %s - Actual: %s' % (p, cls))\n",
    "\n",
    "opts = dict(fontsize={'title': '8pt'}, xaxis=None, yaxis=None, width=250, height=250)\n",
    "hv.Layout([get_prediction(cls).options(**opts) for cls in classes[:20]]).cols(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now numerically for 500 predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntesting = 500\n",
    "choices = np.random.choice(classes, ntesting)\n",
    "class_list = list(classes)\n",
    "\n",
    "prediction = model.predict_generator(gen_samples(choices), steps=ntesting)\n",
    "predictions = classes[prediction.argmax(axis=1)]\n",
    "\n",
    "accuracy = (predictions==choices).sum()/ntesting\n",
    "\n",
    "print(f'Accuracy on test set {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can see how well the classifier performs on the different categories. We'll run 20 predictions on each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(cls, iterations=20):\n",
    "    accurate, predictions = [], []\n",
    "    for i in range(iterations):\n",
    "        sample = get_sample(cls, 'test')\n",
    "        array = get_array(sample)[np.newaxis, ...]\n",
    "        p = model.predict(array).argmax()\n",
    "        p = classes[p]\n",
    "        predictions.append(p)\n",
    "        accurate.append(p == cls)\n",
    "    return np.sum(accurate)/float(iterations), predictions\n",
    "\n",
    "accuracies = [(c, *predict(c)) for c in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize this data as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracies, columns=['landuse', 'accuracy', 'predictions'])\n",
    "\n",
    "hv.Bars(df, 'landuse', 'accuracy').options(width=700, xrotation=45, color_index='landuse', \n",
    "                                           cmap='Category20', show_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting way of viewing this data is to look at which categories the classifier got confused on. We will count how many times the classifier classified one category as another category and visualize the result as a Chord graph where each edge is colored by the predicted category. By clicking on a node we can reveal which other categories incorrectly identified an image as being of that category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame([(p, l) for (_, l, _, ps) in df.itertuples() for p in ps], columns=['Prediction', 'Actual'])\n",
    "graph = pdf.groupby(['Prediction', 'Actual']).size().to_frame().reset_index()\n",
    "\n",
    "hv.Chord(graph.rename(columns={0: 'Count'})).relabel('Misclassification Graph').options(\n",
    "    node_color='index', cmap='Category20', edge_color_index='Actual', label_index='index',\n",
    "    width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clicking on buildings, for instance, reveals a lot of confusion about overpasses, mediumresidential, and intersections, all of which do share visual features in common. Conversely, number of buildings were misidentified as parklots, which is also reasonable. As we saw in the bar chart above, forests on the other hand, have lots of edges leading back to itself, demonstrating the high accuracy observed for that category of images."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
