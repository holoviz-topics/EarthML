{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is made available via `intake` as detailed in [Data Ingestion with Intake](./02_Data_Ingestion_with_Intake.ipynb), the next step is to ensure the data has been appropriately reshaped and aligned across data sources for consumption by the machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be aggregating data across several years using the same Landsat images used in [Walker Lake](../topics/Walker_Lake.ipynb). See that topic for more work on calculating the difference between the water levels over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geoviews as gv\n",
    "\n",
    "hv.extension('bokeh', width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('../catalog.yml')\n",
    "l5_da = cat.l5().read_chunked()\n",
    "l5_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_da = cat.l8().read_chunked()\n",
    "l8_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this EPSG value shown above under the ``crs`` key to create a Cartopy coordinate reference system that we will be using later on in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs=ccrs.epsg(32611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The first step in processing data is to remove the missing values. In this case xarray self-reports the values assigned to `nodatavals`. We can use this information to set the missing values to `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5_da = l5_da.where(l5_da > l5_da.nodatavals[0])\n",
    "l8_da = l8_da.where(l8_da > l8_da.nodatavals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure that no more -9999s show up in the data, by calculating the minimum value in each dataarray as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5_da.min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_da.min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** These operations take a non-trivial amount of time because they require that the data actually be loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute NDVI\n",
    "\n",
    "Now we will calculate NDVI for each of these image sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988 = (l5_da.sel(band=5) - l5_da.sel(band=4)) / (l5_da.sel(band=5) + l5_da.sel(band=4))\n",
    "NDVI_1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_2017 = (l8_da.sel(band=5) - l8_da.sel(band=4)) / (l8_da.sel(band=5) + l8_da.sel(band=4))\n",
    "NDVI_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning data on overlapping grids\n",
    "\n",
    "These two sets of Landsat bands cover roughly the same area but were taken in 1988 and 2017. While they have the same resolution (30m), they have different numbers of grid cells and different x and y offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988.x[0] != NDVI_2017.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat year as name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When these data are combined onto one dataset, the shape of the dataset grows to be the union of the dimensions on each array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset({'1988': NDVI_1988, '2017': NDVI_2017})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly sample one point, such as the center of Walker lake: latitude 38.6942° N, longitude 118.7081° W. First convert the lat, lon (PlareCarree) values to the coordinate reference system of the data (we set this on the `crs` var above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_center, y_center = crs.transform_point(-118.7081, 38.6942, ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll select the data point nearest to this point, and use `.compute()` to actually load that data using `dask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(x=x_center, y=y_center, method='nearest').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the area around the central point as the Region of Interest (ROI). In this case we'll use a 30 km box around the center point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 1.5e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = x_center - buffer\n",
    "xmax = x_center + buffer\n",
    "ymin = y_center - buffer\n",
    "ymax = y_center + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ds.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))\n",
    "ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data are on the same coordinate system, when these data are visualized, the plots can be linked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%opts Image [width=500 height=500] (cmap='viridis')\n",
    "\n",
    "NDVI_1988_p = ROI['1988'].hvplot(clim=(-3, 1), crs=crs, rasterize=True).relabel('1988')\n",
    "NDVI_2017_p = ROI['2017'].hvplot(clim=(-3, 1), crs=crs, rasterize=True).relabel('2017')\n",
    "\n",
    "display(hv.Layout(NDVI_1988_p + NDVI_2017_p).options(shared_axes=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=600 height=500] (cmap='coolwarm')\n",
    "\n",
    "(ROI['2017'] - ROI['1988']).hvplot(crs=crs, clim=(-2, 2), rasterize=True).relabel('Difference in NDVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat year as coords\n",
    "Another way to join the data from the two different years, is by treating the years as coordinates. This approach is more logically sound, but sometimes global attribute data can be lost. For instance if the `crs` were different on the two dataarrays then that attribute would not appear on the output. To work around this, it is sometimes helpful to assign any `attrs` that differ to `coords`. This would look like `NDVI_2017.assign_coords(crs=NDVI_2017.attrs['crs'])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_by_year = xr.concat([NDVI_1988, NDVI_2017], dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "NDVI_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same sampling at a point and select a ROI to demonstrate how years as coords differ from years as names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_by_year.sel(x=x_center, y=y_center, method='nearest').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = NDVI_by_year.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It is simpler to define a series of subplots where the variable that is being iterated over is a coordinate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=500 height=500] (cmap='viridis')\n",
    "\n",
    "p = ROI.hvplot('x','y', col='year', crs=crs, clim=(-3, 1), rasterize=True)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output is a gridspace, we can select a a subplot from the output and alter it in place. For instance, we only really need the colorbar on the second subplot, so we can turn it off for the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[1988] = p[1988].options(colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.diff('year').squeeze().hvplot('x', 'y', crs=crs, cmap='coolwarm', width=600, height=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning data on different grids\n",
    "\n",
    "Suppose that the two sets of Landsat images are on a different grid, which often happens because of differences in how data is collected and processed. To illustrate how to handle this case, we'll manually shift the 2017 coordinates slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_2017['x'] = NDVI_2017.x+15\n",
    "NDVI_2017['y'] = NDVI_2017.y+15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still possible to concatenate the arrays, but the x and y coordinates are now 2 times greater than when the arrays are on the same grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat([NDVI_1988, NDVI_2017],  dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data can be plotted just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ds.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.hvplot('x', 'y', crs=crs, col='year', rasterize=True, cmap='viridis', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the years don't share coordinates, the difference is all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.diff('year').isnull().all().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resolve this we can declare a new grid that spans the entire ROI with the same resolution as the original arrays (30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 30\n",
    "x = np.arange(ROI.x.min(), ROI.x.max(), res)\n",
    "y = np.arange(ROI.y.min(), ROI.y.max(), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use linear interpolation to calculate the values for each grid cell. This operation is not yet supported for dask arrays, so we'll first load in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988.load()\n",
    "NDVI_2017.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the new coordinates defined above to interpolate from the input coordinates to the new grid. The options are `nearest` and `linear` with linear being selected by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_indexed_2017 = NDVI_2017.interp(x=x, y=y)\n",
    "re_indexed_1988 = NDVI_1988.interp(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = xr.concat([re_indexed_1988, re_indexed_2017],  dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.diff('year').squeeze().hvplot('x', 'y', cmap='coolwarm', width=600, height=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next:\n",
    "\n",
    "Now that the data have been aligned and preprocessed appropriately, we can then use them in subsequent steps in a workflow. For instance you might need to learn more about [Resampling](04_Resampling.ipynb). Or you might already be ready for [Machine Learning](05_Machine_Learning.ipynb)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
