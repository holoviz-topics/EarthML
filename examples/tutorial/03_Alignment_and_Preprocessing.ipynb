{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is made available as detailed in [Data Ingestion](./01_Data_Ingestion.ipynb), the next step is to ensure the data has been appropriately reshaped and aligned across data sources for consumption by the machine learning pipeline (or other analysis or simulation steps).\n",
    "\n",
    "We'll be aggregating data across several years, using the same Landsat images used in the [Walker Lake](../topics/Walker_Lake.ipynb) example. See that topic for more work on calculating the difference between the water levels over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geoviews as gv\n",
    "\n",
    "import hvplot.xarray\n",
    "\n",
    "hv.extension('bokeh', width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('../catalog.yml')\n",
    "l5_da = cat.l5().read_chunked()\n",
    "l5_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l8_da = cat.l8().read_chunked()\n",
    "l8_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this EPSG value shown above under the ``crs`` key to create a Cartopy coordinate reference system that we will be using later on in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs=ccrs.epsg(32611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "The first step in processing data is to remove the missing values. In this case xarray self-reports the values assigned to `nodatavals`. We can use this information to set the missing values to `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5_da = l5_da.where(l5_da > l5_da.nodatavals[0])\n",
    "l8_da = l8_da.where(l8_da > l8_da.nodatavals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure that no more -9999s show up in the data, by calculating the minimum value in each DataArray as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', r'All-NaN slice encountered')\n",
    "    l5_min = l5_da.min().compute()\n",
    "    l8_min = l8_da.min().compute()\n",
    "(l5_min, l8_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** These operations take a non-trivial amount of time because they require that the data actually be loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute NDVI\n",
    "\n",
    "Now we will calculate the [NDVI](https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index) (vegetation index) for each of these image sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988 = (l5_da.sel(band=5) - l5_da.sel(band=4)) / (l5_da.sel(band=5) + l5_da.sel(band=4))\n",
    "NDVI_1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_2017 = (l8_da.sel(band=5) - l8_da.sel(band=4)) / (l8_da.sel(band=5) + l8_da.sel(band=4))\n",
    "NDVI_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** To calculate NDVI we have selected based on the band label. In `xarray` you can also select by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Try selecting by index like l8_da[0, 0, 0] or l8_da[0:1, 0:100, 0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine data from overlapping grids\n",
    "\n",
    "These two sets of Landsat bands cover roughly the same area but were taken in 1988 and 2017. While they have the same resolution (30m), they have different numbers of grid cells and different x and y offsets. We can see that by printing the first `x` value for each year and seeing that they are not equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988.x[0].item(), NDVI_2017.x[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating year as DataArray name\n",
    "\n",
    "XArray allows arbitrary data to be combined into one `xr.Dataset`, though if the underlying grids are not aligned, then the shape of the dataset grows to be the union of the dimensions on each array. Here we'll combine the data from different years, providing the year as the name of the underlying DataArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset({'1988': NDVI_1988, '2017': NDVI_2017})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly sample one point, such as the center of Walker lake: latitude 38.6942° N, longitude 118.7081° W. First convert the lat, lon (PlateCarree) values to the coordinate reference system of the data (using the `crs` var we defined above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_center, y_center = crs.transform_point(-118.7081, 38.6942, ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll select the data point nearest to this point, and use `.compute()` to actually load that data using `dask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(x=x_center, y=y_center, method='nearest').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use shift-tab completion to explore different interpolation methods for sel, and try using a different one ('backfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select region of interest\n",
    "\n",
    "We'll use the area around the central point as the Region of Interest (ROI). In this case we'll use a 30 km box around the center point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 1.5e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = x_center - buffer\n",
    "xmax = x_center + buffer\n",
    "ymin = y_center - buffer\n",
    "ymax = y_center + buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ds.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))\n",
    "ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data are on the same coordinate system, when these data are visualized, the plots can be linked. For instance, if you pan one of the plots, the other will pan as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(cmap='viridis', width=500, height=500, crs=crs, rasterize=True)\n",
    "\n",
    "NDVI_1988_p = ROI['1988'].hvplot(clim=(-3, 1), **args).relabel('1988')\n",
    "NDVI_2017_p = ROI['2017'].hvplot(clim=(-3, 1), **args).relabel('2017')\n",
    "\n",
    "(NDVI_1988_p + NDVI_2017_p).options(shared_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Pan around these plots, zoom in and out, reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also subtract the two ROIs, to visualize the difference between 2017 and 1988:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ROI['2017'] - ROI['1988']).hvplot(crs=crs, clim=(-2, 2), rasterize=True,\n",
    "                                   width=600, height=500, cmap='coolwarm').relabel('Difference in NDVI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating year as coords\n",
    "\n",
    "Another way to join the data from the two different years, is by treating the years as coordinates. This approach is more logically sound, but sometimes global attribute data can be lost. For instance if the `crs` were different on the two dataarrays then that attribute would not appear on the output. To work around this, it is sometimes helpful to assign any `attrs` that differ to `coords`. This would look like `NDVI_2017.assign_coords(crs=NDVI_2017.attrs['crs'])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_by_year = xr.concat([NDVI_1988, NDVI_2017], dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "NDVI_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same sampling at a point and select a ROI to demonstrate how years as coords differ from years as names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_by_year.sel(x=x_center, y=y_center, method='nearest').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = NDVI_by_year.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It is simpler to define a series of subplots where the variable that is being iterated over is a coordinate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ROI.hvplot('x','y', col='year', clim=(-3, 1), dynamic=False, **args)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output is a gridspace, we can select a a subplot from the output and alter it in place. For instance, we only really need the colorbar on the second subplot, so we can turn it off for the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[1988] = p[1988].options(colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.diff('year').squeeze().hvplot('x', 'y', crs=crs, cmap='coolwarm', width=600, height=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning data on different grids\n",
    "\n",
    "Suppose that the two sets of Landsat images are on a different grid, which often happens because of differences in how data is collected and processed. To illustrate how to handle this case, we'll manually shift the 2017 coordinates slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_2017['x'] = NDVI_2017.x+15\n",
    "NDVI_2017['y'] = NDVI_2017.y+15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still possible to concatenate the arrays, but the x and y coordinates are now 2 times greater than when the arrays are on the same grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat([NDVI_1988, NDVI_2017],  dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use .shape to look at the shape of NDVI_by_year defined above compared to the ds that we just defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data can be plotted just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = ds.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.hvplot('x', 'y', col='year', **args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the years don't share coordinates, the difference is all NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI.diff('year').isnull().all().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To resolve this we can declare a new grid that spans the entire ROI with the same resolution as the original arrays (30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 30\n",
    "x = np.arange(ROI.x.min(), ROI.x.max(), res)\n",
    "y = np.arange(ROI.y.min(), ROI.y.max(), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use linear interpolation to calculate the values for each grid cell. This operation is not yet supported for dask arrays, so we'll first load in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_1988.load()\n",
    "NDVI_2017.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the new coordinates defined above to interpolate from the input coordinates to the new grid. The options are `nearest` and `linear` with linear being selected by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_indexed_2017 = NDVI_2017.interp(x=x, y=y)\n",
    "re_indexed_1988 = NDVI_1988.interp(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Try using linear interpolation instead of nearest. Use tab and shift-tab for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = xr.concat([re_indexed_1988, re_indexed_2017],  dim=xr.DataArray([1988, 2017], dims=('year'), name='year'))\n",
    "ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot the difference between the two years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Plot the difference between the two years using the same approach as we used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next:\n",
    "\n",
    "Now that the data have been aligned and preprocessed appropriately, we can then use them in subsequent steps in a workflow. For instance you might need to learn more about [Resampling](04_Resampling.ipynb). Or you might already be ready for [Machine Learning](05_Machine_Learning.ipynb)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
